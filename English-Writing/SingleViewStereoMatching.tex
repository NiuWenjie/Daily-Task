\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{booktabs}
\usepackage{indentfirst}
\usepackage{epsfig}
\usepackage{float}
\usepackage{picinpar,graphicx}
\usepackage[breaklinks=true,bookmarks=false,colorlinks,
            linkcolor=red,
            anchorcolor=blue,
            citecolor=green,
            backref=page]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}


\begin{document}

%%%%%%%%% TITLE
\title{Single View Stereo Matching}

\author{Wenjie Niu\\\\ July 6,2018}

\maketitle
%\thispagestyle{empty}

%%%A%%%%%% ABSTRACT
\begin{abstract}
This paper show for the first time that the monocular depth estimation problem can be reformulated as two sub-problems, a view synthesis procedure followed by stereo matching, with two intriguing properties, namely i) geometrical constraints can be explicitly imposed during inference; ii) demand on labelled depth data can be greatly alleviated.\par
It's showed that the whole pipeline can still be trained in an end-to-end fashion and this new formulation plays a critical role in advancing the performance. The resulting model outperforms all the previous monocular depth estimation method as well as the stereo block matching method in the challenging KITTI data set by only using a small number of real training data.\par
\end{abstract}

\begin{figure}[!htp]
\begin{center}
   \includegraphics[width=1\linewidth]{MonocularDepthEstimation.png}
\end{center}
   \caption{Pipeline of our approach on monocular depth estimation. We decompose the task into two parts: view synthesis and stereo matching. Both networks enforce the geometric reasoning capacity. With this new formulation, our approach is able to achieve state-of-the-art performance.\cite{Luo_2018_CVPR}}
\label{fig:Estimation}
\end{figure}

%%%%%%%%% BODY TEXT
\section{Introduction}
Authors take a novel perspective and show for the first time that monocular depth estimation problem can be formulated as a stereo matching problem in which the right view is automatically generated by a high-quality view synthesis network. The whole pipeline is shown in figure.~\ref{fig:Estimation}. The key insights here are that i) both view synthesis and stereo matching respect the underlying geometric principles; ii) both of them can be trained without using the expensive real depth data and thus generated well; iii) the whole pipeline can be collectively trained in an end-to-end fashion that optimize the geometrically correct objectives. The method in this paper is similar idea as revealed in the Spatial Transformation Network~\cite{NIPS2015_5854}.\par

\begin{figure*}
\begin{center}
   \includegraphics[width=1\linewidth]{DetailsofNetwork.png}
\end{center}
   \caption{Details of our single view stereo matching network. Upper part is the view synthesis network. The input image is first processed by a CNN. It results in probabilistic disparity maps that help to reconstruct a synthetic right view by selectively taking pixels from nearby locations on the original left image. A stereo matching network, which is shown on the lower part of the figure, then takes both the original left image and synthetic right image to calculate an accurate disparity, which can be transformed into a corresponding depth map given the camera settings~\cite{Luo_2018_CVPR}.}
\label{fig:Detail}
\end{figure*}

\section{Analysis and Approach}
The whole pipeline is shown in figure.~\ref{fig:Detail}. By tracking this problem using two seperate steps, the paper find that both procedures obey primary geometric principles and they can trained without expensive data supply. In order to better utilize the geometric relation between two views, the paper take the idea if 1D correlation employed in DispNetC~\cite{Mayer_2016_CVPR}. The further adopt the DispFullNet structure mentioned in~\cite{Pang2017Cascade} to achieve full resolution prediction.\par
Their view synthesis network is shown in the upper part of figure.~\ref{fig:Detail}. This network is develoed based on Deep3D~[37] model.The operation of selection is the core component in this network. This model is also illustrated in figure.~\ref{fig:Detail}. Denote $I_l$ as the input left image, previous Depth Image-Based Rendering (DIBR) techniques choose to directly warp the left image based on estimated disparity into a corresponding right image. Suppose $D$ is the predicted disparity aligned with the left image, the procedure can be formulate as Eq:~\ref{Eq:i}
\begin{equation}
\tilde{I_r}(i,j-D_{i,j})=I_l(i,j),\quad (i,j)\in\omega_l
\label{Eq:i}
\end{equation}
where $\omega_l$ is the image space of $I_l$ and $i$, $j$ refer to the row and column on $I_l$ respectively.\par

\section{Conclusions}
We explicitly encode the geometric transformation within both networks to better tackle the problems individually. Collectively training the whole pipeline results in an overall boost and we prove that both networks are able to preserve their original functionality after end-to-end training. Without using a large amount of expensive ground truth labels, we outperform all previous methods on a monocular depth estimation benchmark. Remarkably, we are the first to outperform the stereo blocking matching algorithm on a stereo matching benchmark using a monocular method.\par
%-------------------------------------------------------------------------

{\small
\bibliographystyle{ieee}
\bibliography{SingleViewStereoMatching}
}

\end{document}
